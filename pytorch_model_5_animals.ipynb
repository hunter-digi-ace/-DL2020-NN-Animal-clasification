{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda env:pytorch-image-classification] *","language":"python","name":"conda-env-pytorch-image-classification-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"pytorch_model_dani_5_animals.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2oaUwrOXh1cW","colab_type":"text"},"source":["# Image Classification of Dogs vs. Cats With PyTorch"]},{"cell_type":"markdown","metadata":{"id":"-T-OGIIYh1cY","colab_type":"text"},"source":["### Imports & Environment"]},{"cell_type":"code","metadata":{"id":"ywQP61SWh1cZ","colab_type":"code","outputId":"a2d3e246-36f1-471a-e4fe-fed63d4d5b67","executionInfo":{"status":"ok","timestamp":1592046198264,"user_tz":-120,"elapsed":1117,"user":{"displayName":"EDGAR GIL","photoUrl":"","userId":"09028541672129200509"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import os\n","import random\n","import collections\n","import shutil\n","import time\n","import glob\n","import csv\n","import numpy as np\n","\n","import torch\n","import torch.backends.cudnn as cudnn\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","from PIL import Image\n","\n","from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/Shared drives/DANI IVAN EDGAR MARÇAL/DEEPLEARNING/Edgar - Dani/Deep_Learning2020/final/try2\n","\n","ROOT_DIR = os.getcwd()\n","DATA_HOME_DIR = ROOT_DIR + '/data_5_animals'\n","\n","\n","\n","#%cd  valid"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/Shared drives/DANI IVAN EDGAR MARÇAL/DEEPLEARNING/Edgar - Dani/Deep_Learning2020/final/try2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YO_CUIwRh1cm","colab_type":"text"},"source":["### Config & Hyperparameters"]},{"cell_type":"code","metadata":{"id":"nqIDRaSHh1cn","colab_type":"code","colab":{}},"source":["# paths\n","data_path = DATA_HOME_DIR + '/' \n","split_train_path = data_path + '/train/'\n","full_train_path = data_path + '/train_full/'\n","valid_path = data_path + '/validation/'\n","test_path = DATA_HOME_DIR + '/test/test/'\n","saved_model_path = ROOT_DIR + '/models/'\n","submission_path = ROOT_DIR + '/submissions/'\n","\n","\n","# data\n","\n","\n","# model\n","nb_runs = 1\n","nb_aug = 3\n","\n","lr = 1e-4\n","clip = 0.001\n","#can change this\n","archs = [\"resnet101\"]\n","#archs = [\"vgg11\"]\n","#pretrainedModel=False\n","pretrainedModel=True\n","epochs = 10\n","batch_size = 128\n","#--\n","model_names = sorted(name for name in models.__dict__ if name.islower() and not name.startswith(\"__\"))\n","best_prec1 = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1ED7Nsrh1cu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":850},"outputId":"8823e5bd-40aa-4cea-998f-4e822eeeb21e","executionInfo":{"status":"ok","timestamp":1592046198999,"user_tz":-120,"elapsed":1785,"user":{"displayName":"EDGAR GIL","photoUrl":"","userId":"09028541672129200509"}}},"source":["model_names"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['_utils',\n"," 'alexnet',\n"," 'densenet',\n"," 'densenet121',\n"," 'densenet161',\n"," 'densenet169',\n"," 'densenet201',\n"," 'detection',\n"," 'googlenet',\n"," 'inception',\n"," 'inception_v3',\n"," 'mnasnet',\n"," 'mnasnet0_5',\n"," 'mnasnet0_75',\n"," 'mnasnet1_0',\n"," 'mnasnet1_3',\n"," 'mobilenet',\n"," 'mobilenet_v2',\n"," 'quantization',\n"," 'resnet',\n"," 'resnet101',\n"," 'resnet152',\n"," 'resnet18',\n"," 'resnet34',\n"," 'resnet50',\n"," 'resnext101_32x8d',\n"," 'resnext50_32x4d',\n"," 'segmentation',\n"," 'shufflenet_v2_x0_5',\n"," 'shufflenet_v2_x1_0',\n"," 'shufflenet_v2_x1_5',\n"," 'shufflenet_v2_x2_0',\n"," 'shufflenetv2',\n"," 'squeezenet',\n"," 'squeezenet1_0',\n"," 'squeezenet1_1',\n"," 'utils',\n"," 'vgg',\n"," 'vgg11',\n"," 'vgg11_bn',\n"," 'vgg13',\n"," 'vgg13_bn',\n"," 'vgg16',\n"," 'vgg16_bn',\n"," 'vgg19',\n"," 'vgg19_bn',\n"," 'video',\n"," 'wide_resnet101_2',\n"," 'wide_resnet50_2']"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"akEAoopNh1c2","colab_type":"text"},"source":["### Helper Functions for Training"]},{"cell_type":"code","metadata":{"id":"Wg39wEdkh1c4","colab_type":"code","colab":{}},"source":["def train(train_loader, model, criterion, optimizer, epoch):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    acc = AverageMeter()\n","    end = time.time()\n","    \n","    # switch to train mode\n","    model.train()\n","    \n","    for i, (images, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","  \n","        print(\"inside train \"+str(i))\n","        target = target.cuda()\n","        image_var = torch.autograd.Variable(images)\n","        label_var = torch.autograd.Variable(target)\n","\n","        # compute y_pred\n","        y_pred = model(image_var)\n","        loss = criterion(y_pred, label_var)\n","       # loss.requires_grad = True\n","\n","        # measure accuracy and record loss\n","        prec1, temp_var = accuracy(y_pred, target, topk=(1, 1))\n","        losses.update(loss, images.size(0))\n","        acc.update(prec1, images.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9N51W9zvh1dB","colab_type":"code","colab":{}},"source":["def validate(val_loader, model, criterion, epoch):\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","    acc = AverageMeter()\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    for i, (images, labels) in enumerate(val_loader):\n","        labels = labels.cuda()\n","        \n","        print(\"inside validate \"+str(i))\n","        image_var = torch.autograd.Variable(images)\n","        label_var = torch.autograd.Variable(labels)\n","\n","        # compute y_pred\n","        y_pred = model(image_var)\n","        loss = criterion(y_pred, label_var)\n","        \n","        #loss.requires_grad = True\n","\n","        # measure accuracy and record loss\n","        prec1, temp_var = accuracy(y_pred, labels, topk=(1, 1))\n","        losses.update(loss, images.size(0))\n","        acc.update(prec1, images.size(0))\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","    print('   * EPOCH {epoch} | Accuracy: {acc.avg:.3f} | Loss: {losses.avg:.3f}'.format(epoch=epoch,\n","                                                                                         acc=acc,\n","                                                                                         losses=losses))\n","\n","    return acc.avg"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nV8YYPwDh1dI","colab_type":"code","colab":{}},"source":["def test(test_loader, model):\n","    csv_map = collections.defaultdict(float)\n","    csv_type = []\n","    # switch to evaluate mode\n","    model.eval()\n","    \n","    for aug in range(nb_aug):\n","        print(\"   * Predicting on test augmentation {}\".format(aug + 1))\n","        \n","        for i, (images, filepath) in enumerate(test_loader):\n","            # pop extension, treat as id to map\n","            filepath = os.path.splitext(os.path.basename(filepath[0]))[0]\n","            \n","            print(\"inside test \"+filepath)\n","            #filepath = int(filepath)\n","\n","            print(\"inside test \"+str(i))\n","\n","\n","            image_var = torch.autograd.Variable(images)\n","            y_pred = model(image_var)\n","            # get the index of the max log-probability\n","            smax = nn.Softmax()\n","            smax_out = smax(y_pred)[0]\n","            ardilla_prob = smax_out.data[0]\n","            caballo_prob = smax_out.data[1]\n","            elefante_prob = smax_out.data[2]\n","            mariposa_prob = smax_out.data[3]\n","            oveja_prob = smax_out.data[4]\n","            print(\"this image \" + filepath + \" have: \")\n","\n","            string1=np.around(ardilla_prob.cpu(), decimals=4)\n","            string1 = np.clip(string1, clip, 1-clip)\n","            print(\"ardilla \" + str(string1.data.cpu().numpy().round(decimals=4)) + \"\")\n","\n","            string2=np.around(caballo_prob.cpu(), decimals=4)\n","            string2 = np.clip(string2, clip, 1-clip)\n","            print(\"caballo \" + str(string2.data.cpu().numpy().round(decimals=4))  + \"\")\n","\n","            string3=np.around(elefante_prob.cpu(), decimals=4)\n","            string3 = np.clip(string3, clip, 1-clip)\n","            print(\"elefante \" + str(string3.data.cpu().numpy().round(decimals=4))  + \"\")\n","\n","            string4=np.around(mariposa_prob.cpu(), decimals=4)\n","            string4 = np.clip(string4, clip, 1-clip)\n","            print(\"mariposa \" + str(string4.data.cpu().numpy().round(decimals=4)) + \"\")\n","\n","            string5=np.around(oveja_prob.cpu(), decimals=4)\n","            string5 = np.clip(string5, clip, 1-clip)\n","            print(\"oveja \" + str(string5.data.cpu().numpy().round(decimals=4))  + \"\")\n","\n","            ##############################################################\n","            #prob = dog_prob\n","            #if cat_prob > dog_prob:\n","            #    prob = 1 - cat_prob\n","            #prob = np.around(prob.cpu(), decimals=4)\n","            #prob = np.clip(prob, clip, 1-clip)\n","            # mirar como añadir mas columnas csv_map[filepath] += (\"ardilla\")\n","            lista = [ardilla_prob, caballo_prob, elefante_prob, mariposa_prob, oveja_prob]\n","            index = lista.index(max(lista))\n","            maximo = max(lista)\n","            if index == 0:\n","                csv_map[filepath] += (string1.data.cpu().numpy() / nb_aug)\n","                if maximo > 0.55:\n","                  csv_type.append(\"es una ardilla\")\n","                else:\n","                  csv_type.append(\"puede ser ardilla\")\n","            elif index == 1:\n","                csv_map[filepath] += (string2.data.cpu().numpy() / nb_aug)\n","                if maximo > 0.55:\n","                  csv_type.append(\"es un caballo\")\n","                else:\n","                  csv_type.append(\"puede ser caballo\")\n","\n","            elif index == 2:\n","                csv_map[filepath] += (string3.data.cpu().numpy() / nb_aug)\n","                if maximo > 0.55:\n","                  csv_type.append(\"es un elefante\")\n","                else:\n","                  csv_type.append(\"puede ser elefante\")\n","\n","            elif index == 3:\n","                csv_map[filepath] += (string4.data.cpu().numpy() / nb_aug)\n","                if maximo > 0.55:\n","                  csv_type.append(\"es una mariposa\")\n","                else:\n","                  csv_type.append(\"puede ser mariposa\")\n","\n","            elif index == 4:\n","                csv_map[filepath] += (string5.data.cpu().numpy() / nb_aug)\n","                if maximo > 0.55:\n","                  csv_type.append(\"es una oveja\")\n","                else:\n","                  csv_type.append(\"puede ser oveja\")\n","            \n","            csv_map[filepath] = csv_map[filepath].round(decimals=4)\n","            #csv_map[filepath] += (string1.data.cpu().numpy() / nb_aug).round(decimals=4)\n","            #csv_type.append(\"ardilla\")\n","            ##############################################################\n","\n","    sub_fn = submission_path + '60_{0}epoch_{1}clip_{2}runs'.format(epochs, clip, nb_runs)\n","    \n","    for arch in archs:\n","        sub_fn += \"_{}\".format(arch)\n","        \n","    print(\"Writing Predictions to CSV...\")\n","    with open(sub_fn + '.csv', 'w') as csvfile:\n","        fieldnames = ['id', 'porcentaje', 'tipo']\n","        csv_w = csv.writer(csvfile, delimiter=',')\n","        csv_w.writerow(('id', 'porcentaje', 'tipo'))\n","        for index, row in enumerate(sorted(csv_map.items())):\n","            csv_w.writerow([row, csv_type[index]])\n","    print(\"Done.\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eExm03bAh1dS","colab_type":"code","colab":{}},"source":["def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n","    torch.save(state, filename)\n","    if is_best:\n","        shutil.copyfile(filename, 'model_best_dani.pth.tar')      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrXM6RsEh1dd","colab_type":"code","colab":{}},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZkiacFwh1dl","colab_type":"code","colab":{}},"source":["def adjust_learning_rate(optimizer, epoch):\n","    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n","    global lr\n","    lr = lr * (0.1**(epoch // 30))\n","    for param_group in optimizer.state_dict()['param_groups']:\n","        param_group['lr'] = lr\n","\n","\n","def accuracy(y_pred, y_actual, topk=(1, )):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = y_actual.size(0)\n","\n","    _, pred = y_pred.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(y_actual.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","\n","    return res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qd4a-JXMh1du","colab_type":"code","colab":{}},"source":["class TestImageFolder(data.Dataset):\n","    def __init__(self, root, transform=None):\n","        images = []\n","        for filename in sorted(glob.glob(test_path + \"*.jpeg\")):\n","            images.append('{}'.format(filename))\n","\n","        self.root = root\n","        self.imgs = images\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        filename = self.imgs[index]\n","        img = Image.open(os.path.join(self.root, filename))\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        return img, filename\n","\n","    def __len__(self):\n","        return len(self.imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEpC09knh1d3","colab_type":"code","colab":{}},"source":["def shear(img):\n","    width, height = img.size\n","    m = random.uniform(-0.05, 0.05)\n","    xshift = abs(m) * width\n","    new_width = width + int(round(xshift))\n","    img = img.transform((new_width, height), Image.AFFINE,\n","                        (1, m, -xshift if m > 0 else 0, 0, 1, 0),\n","                        Image.BICUBIC)\n","    return img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-p9vZfnEh1eC","colab_type":"text"},"source":["### Main Training Loop"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Kb9Y8euEh1eD","colab_type":"code","colab":{}},"source":["def main(mode=\"train\", resume=False):\n","    \n","    global best_prec1\n","    \n","    for arch in archs:\n","\n","        # create model\n","        print(\"=> Starting {0} on '{1}' model\".format(mode, arch))\n","        model = models.__dict__[arch](pretrained=pretrainedModel)\n","        # Don't update non-classifier learned features in the pretrained networks\n","        for param in model.parameters():\n","            param.requires_grad = False\n","        # Replace the last fully-connected layer\n","        # Parameters of newly constructed modules have requires_grad=True by default\n","        # Final dense layer needs to replaced with the previous out chans, and number of classes\n","        # in this case -- resnet 101 - it's 2048 with two classes (cats and dogs)\n","        \n","        if arch.startswith('resnet'):\n","          model.fc = nn.Linear(2048, 5)\n","        if arch.startswith('vgg11'):\n","          model.classifier[6]=nn.Linear(4096, 5)\n","\n","        if arch.startswith('alexnet') or arch.startswith('vgg'):\n","            model.features = torch.nn.DataParallel(model.features)\n","            model.cuda()\n","        else:\n","            model = torch.nn.DataParallel(model).cuda()\n","            \n","        # optionally resume from a checkpoint\n","        if resume:\n","            if os.path.isfile(resume):\n","                print(\"=> Loading checkpoint '{}'\".format(resume))\n","                checkpoint = torch.load(resume)\n","                start_epoch = checkpoint['epoch']\n","                best_prec1 = checkpoint['best_prec1']\n","                model.load_state_dict(checkpoint['state_dict'])\n","                print(\"=> Loaded checkpoint (epoch {})\".format(checkpoint['epoch']))\n","            #else:\n","                #print(\"=> No checkpoint found at '{}'\".format(args.resume))\n","\n","        cudnn.benchmark = True\n","\n","        # Data loading code\n","        traindir = split_train_path\n","        valdir = valid_path\n","        testdir = test_path\n","\n","        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","        train_loader = data.DataLoader(\n","            datasets.ImageFolder(traindir,\n","                                 transforms.Compose([\n","                                     # transforms.Lambda(shear),\n","                                     transforms.RandomResizedCrop(224),\n","                                     transforms.RandomHorizontalFlip(),\n","                                     transforms.ToTensor(),\n","                                     normalize,\n","                                 ])),\n","            batch_size=batch_size,\n","            shuffle=True,\n","            num_workers=4,\n","            pin_memory=False)\n","\n","        val_loader = data.DataLoader(\n","            datasets.ImageFolder(valdir,\n","                                 transforms.Compose([\n","                                     transforms.Resize(256),\n","                                     transforms.CenterCrop(224),\n","                                     transforms.ToTensor(),\n","                                     normalize,\n","                                 ])),\n","            batch_size=batch_size,\n","            shuffle=True,\n","            num_workers=4,\n","            pin_memory=False)\n","\n","        test_loader = data.DataLoader(\n","            TestImageFolder(testdir,\n","                            transforms.Compose([\n","                                # transforms.Lambda(shear),\n","                                transforms.Resize(256),\n","                                transforms.CenterCrop(224),\n","                                transforms.RandomHorizontalFlip(),\n","                                transforms.ToTensor(),\n","                                normalize,\n","                            ])),\n","            batch_size=1,\n","            shuffle=False,\n","            num_workers=1,\n","            pin_memory=False)\n","        \n","        \n","        if mode == \"test\":\n","            test(test_loader, model)\n","            return\n","        \n","        # define loss function (criterion) and pptimizer\n","        criterion = nn.CrossEntropyLoss().cuda()\n","        \n","        if mode == \"validate\":\n","            validate(val_loader, model, criterion, 0)\n","            return\n","\n","        print(model)\n","      \n","        if arch.startswith('resnet'):\n","          optimizer = optim.Adam(model.module.fc.parameters(), lr, weight_decay=1e-4)\n","        if arch.startswith('vgg11'):\n","          optimizer = optim.Adam(model.parameters(), lr, weight_decay=1e-4)\n","       \n","       \n","\n","        for epoch in range(epochs):\n","            adjust_learning_rate(optimizer, epoch)\n","\n","            # train for one epoch\n","            train(train_loader, model, criterion, optimizer, epoch)\n","\n","            # evaluate on validation set\n","            prec1 = validate(val_loader, model, criterion, epoch)\n","\n","            # remember best Accuracy and save checkpoint\n","            is_best = prec1 > best_prec1\n","            best_prec1 = max(prec1, best_prec1)\n","            save_checkpoint({\n","                'epoch': epoch + 1,\n","                'arch': arch,\n","                'state_dict': model.state_dict(),\n","                'best_prec1': best_prec1,\n","            }, is_best)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-HGzi4bKh1eJ","colab_type":"text"},"source":["### Run Train"]},{"cell_type":"code","metadata":{"id":"GdH6BdPah1eL","colab_type":"code","outputId":"b870d310-f150-4f43-cf00-2ecaf99a6a6a","executionInfo":{"status":"error","timestamp":1592046268088,"user_tz":-120,"elapsed":70595,"user":{"displayName":"EDGAR GIL","photoUrl":"","userId":"09028541672129200509"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["main(mode=\"train\")"],"execution_count":39,"outputs":[{"output_type":"stream","text":["=> Starting train on 'vgg11' model\n","VGG(\n","  (features): DataParallel(\n","    (module): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (4): ReLU(inplace=True)\n","      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (7): ReLU(inplace=True)\n","      (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (9): ReLU(inplace=True)\n","      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (12): ReLU(inplace=True)\n","      (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (14): ReLU(inplace=True)\n","      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","      (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (17): ReLU(inplace=True)\n","      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (19): ReLU(inplace=True)\n","      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=5, bias=True)\n","  )\n",")\n","inside train 0\n","inside train 1\n","inside train 2\n","inside train 3\n","inside train 4\n","inside train 5\n","inside train 6\n","inside train 7\n","inside train 8\n","inside train 9\n","inside train 10\n","inside train 11\n","inside train 12\n","inside train 13\n","inside train 14\n","inside train 15\n","inside train 16\n","inside train 17\n","inside train 18\n","inside train 19\n","inside train 20\n","inside train 21\n","inside train 22\n","inside train 23\n","inside train 24\n","inside train 25\n","inside train 26\n","inside train 27\n","inside train 28\n","inside train 29\n","inside train 30\n","inside train 31\n","inside train 32\n","inside train 33\n","inside train 34\n","inside train 35\n","inside train 36\n","inside train 37\n","inside validate 0\n","inside validate 1\n","inside validate 2\n","inside validate 3\n","inside validate 4\n","inside validate 5\n","inside validate 6\n","inside validate 7\n","inside validate 8\n","inside validate 9\n","inside validate 10\n","inside validate 11\n","   * EPOCH 0 | Accuracy: 20.000 | Loss: 1.603\n","inside train 0\n","inside train 1\n","inside train 2\n","inside train 3\n","inside train 4\n","inside train 5\n","inside train 6\n","inside train 7\n","inside train 8\n","inside train 9\n","inside train 10\n","inside train 11\n","inside train 12\n","inside train 13\n","inside train 14\n","inside train 15\n","inside train 16\n","inside train 17\n","inside train 18\n","inside train 19\n","inside train 20\n","inside train 21\n","inside train 22\n","inside train 23\n","inside train 24\n","inside train 25\n","inside train 26\n","inside train 27\n","inside train 28\n","inside train 29\n","inside train 30\n","inside train 31\n","inside train 32\n","inside train 33\n","inside train 34\n","inside train 35\n","inside train 36\n","inside train 37\n","inside validate 0\n","inside validate 1\n","inside validate 2\n","inside validate 3\n","inside validate 4\n","inside validate 5\n","inside validate 6\n","inside validate 7\n","inside validate 8\n","inside validate 9\n","inside validate 10\n","inside validate 11\n","   * EPOCH 1 | Accuracy: 20.467 | Loss: 1.600\n","inside train 0\n","inside train 1\n","inside train 2\n","inside train 3\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-277c01e2c1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-38-c697391e26b3>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(mode, resume)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-6b013301a11c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"dk6Y_sLNh1eQ","colab_type":"code","colab":{}},"source":["main(mode=\"validate\", resume='model_best_dani.pth.tar')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4eW414Hh1eX","colab_type":"text"},"source":["### Run Test"]},{"cell_type":"code","metadata":{"id":"eKlAGVI1h1eY","colab_type":"code","colab":{}},"source":["main(mode=\"test\", resume='model_best_dani.pth.tar')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pG8KpqPMh1ed","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}